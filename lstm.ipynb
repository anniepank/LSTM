{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('local')"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data has 1115394 characters, 65 unique.\n"
     ]
    }
   ],
   "source": [
    "# data I/O\n",
    "data = open('input.txt', 'r').read()  # should be simple plain text file\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "char_to_ix = {ch: i for i, ch in enumerate(chars)}\n",
    "ix_to_char = {i: ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hidden_size = 100\n",
    "seq_length = 25 \n",
    "learning_rate = 1e-1\n",
    "\n",
    "weight_std = 0.01\n",
    "weight_mean = 0.0\n",
    "\n",
    "Wf = np.random.randn(hidden_size, vocab_size + hidden_size) * weight_std + weight_mean\n",
    "Wi = np.random.randn(hidden_size, vocab_size + hidden_size) * weight_std + weight_mean\n",
    "Wo = np.random.randn(hidden_size, vocab_size + hidden_size) * weight_std + weight_mean\n",
    "Wg = np.random.randn(hidden_size, vocab_size + hidden_size) * weight_std + weight_mean\n",
    "\n",
    "Wy = np.random.randn(vocab_size, hidden_size) * weight_std\n",
    "\n",
    "bf = np.zeros((hidden_size, 1))  # forget bias\n",
    "bi = np.zeros((hidden_size, 1))  # input bias\n",
    "bo = np.zeros((hidden_size, 1))  # output gate bias\n",
    "bg = np.zeros((hidden_size, 1))  # cell state bias\n",
    "\n",
    "by = np.zeros((vocab_size, 1))\n",
    "\n",
    "params = {\n",
    "    'Wf': Wf, 'Wi': Wi, 'Wo': Wo, 'Wg': Wg, 'Wy': Wy, \n",
    "    'bf': bf, 'bi': bi, 'bo': bo, 'bg': bg, 'by': by\n",
    "}\n",
    "\n",
    "for key in list(params.keys()):\n",
    "    params['d' + key] = np.zeros_like(params[key])\n",
    "\n",
    "for key in list(params.keys()):\n",
    "    if key[0] != 'd':\n",
    "        params['m_' + key] = np.zeros_like(params[key])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def zero_grad(params):\n",
    "    for key in list(params.keys()):\n",
    "        if key[0] == 'd':\n",
    "            params[key] = np.zeros_like(params[key])\n",
    "\n",
    "\n",
    "def clip_grad(params):\n",
    "    for key in list(params.keys()):\n",
    "        if key[0] == 'd':\n",
    "            np.clip(params[key], -1, 1, out=params[key])\n",
    "\n",
    "\n",
    "def forward(x, hprev, cprev, params):\n",
    "    z = np.row_stack((hprev, x))\n",
    "    \n",
    "    zf = params['Wf'] @ z + params['bf']\n",
    "    zi = params['Wi'] @ z + params['bi']\n",
    "    zo = params['Wo'] @ z + params['bo']\n",
    "    zg = params['Wg'] @ z + params['bg']\n",
    "    \n",
    "    f = sigmoid(zf)\n",
    "    i = sigmoid(zi)    \n",
    "    o = sigmoid(zo)\n",
    "    g = np.tanh(zg)\n",
    "\n",
    "    c = f * cprev +  i * g\n",
    "    h = o * np.tanh(c)\n",
    "\n",
    "    y = params['Wy'] @ h + params['by']\n",
    "    p = np.exp(y) / np.sum(np.exp(y))\n",
    "\n",
    "    cache = z, f, i, g, o, c, h, y, p\n",
    "\n",
    "    return cache, params\n",
    "\n",
    "\n",
    "def backward(target, dhnext, dcnext, cprev, cache, params):\n",
    "    z, f, i, g, o, c, h, y, p = cache\n",
    "    dy = np.copy(p)\n",
    "    dy[target] -= 1  \n",
    "\n",
    "    params['dWy'] += dy @ h.T\n",
    "    params['dby'] += dy\n",
    "    \n",
    "    dh = params['Wy'].T @ dy + dhnext\n",
    "    \n",
    "    do = dh * np.tanh(c)\n",
    "    dzo = o * (1 - o) * do\n",
    "    params['dWo'] += dzo @ z.T\n",
    "    params['dbo'] += dzo\n",
    "\n",
    "    dc = np.copy(dcnext)\n",
    "    dc += dh * o * (1 - np.tanh(c) * np.tanh(c))\n",
    "\n",
    "    dg = dc * i\n",
    "    dzg = dg * (1 - g ** 2)\n",
    "    params['dWg'] += dzg @ z.T\n",
    "    params['dbg'] += dzg\n",
    "\n",
    "    di = dc * g\n",
    "    dzi = i * (1 - i) * di\n",
    "    params['dWi'] += dzi @ z.T\n",
    "    params['dbi'] += dzi\n",
    "\n",
    "    df = dc * cprev \n",
    "    dzf = f * (1 - f) * df\n",
    "    params['dWf'] += dzf @ z.T\n",
    "    params['dbf'] += dzf\n",
    "\n",
    "    dz = params['Wf'].T @ dzf + params['Wi'].T @ dzi +  params['Wg'].T @ dzg +  params['Wo'].T @ dzo\n",
    "    dhprev = dz[:hidden_size, :]\n",
    "    dcprev = f * dc\n",
    "    return dhprev, dcprev, params\n",
    "\n",
    "\n",
    "def lossFun(inputs, targets, hprev, cprev, params):\n",
    "    xs, hs, cs, zs, ys, ps, fs, is_, os, gs = {}, {}, {}, {}, {}, {}, {}, {}, {}, {}\n",
    "    hs[-1] = np.copy(hprev)\n",
    "    cs[-1] = np.copy(cprev)\n",
    "    loss = 0\n",
    "    \n",
    "    for t in range(len(inputs)):\n",
    "        xs[t] = np.zeros((vocab_size, 1))\n",
    "        xs[t][inputs[t]] = 1\n",
    "\n",
    "        cache, params = forward(xs[t], hs[t - 1], cs[t - 1], params)\n",
    "        zs[t], fs[t], is_[t], gs[t], os[t], cs[t], hs[t], ys[t], ps[t] = cache\n",
    "    \n",
    "        loss += -np.log(ps[t][targets[t], 0]) \n",
    "    \n",
    "    zero_grad(params)\n",
    "    \n",
    "    dhnext = np.zeros_like(hs[0])\n",
    "    dcnext = np.zeros_like(cs[0])\n",
    "\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        cache = (zs[t], fs[t], is_[t], gs[t], os[t], cs[t], hs[t], ys[t], ps[t] )\n",
    "        dhnext, dcnext, params = backward(targets[t], dhnext, dcnext, cs[t - 1], cache, params)\n",
    "\n",
    "    clip_grad(params)\n",
    "    \n",
    "       \n",
    "    return loss, hs[len(inputs) - 1], cs[len(inputs) - 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample(h, c, first_letter_idx, n, params):\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[first_letter_idx] = 1\n",
    "    \n",
    "    indexes = []\n",
    "    for _ in range(n):\n",
    "        cache, params = forward(x, h, c, params)\n",
    "        c = cache[-4]\n",
    "        h = cache[-3]\n",
    "        p = cache[-1]\n",
    "        \n",
    "        letter_index = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "        x = np.zeros((vocab_size, 1))\n",
    "        x[letter_index] = 1\n",
    "        indexes.append(letter_index)\n",
    "\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-de052869d875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msample_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----\\n %s \\n----'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-07df6292c60d>\u001b[0m in \u001b[0;36msample\u001b[0;34m(h, c, first_letter_idx, n, params)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-b7acec257480>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hprev, cprev, params)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "\n",
    "n, p = 0, 0\n",
    "smooth_loss = -np.log(1.0 / vocab_size) * seq_length \n",
    "\n",
    "while True:\n",
    "    if p + seq_length + 1 >= len(data) or n == 0:\n",
    "        hprev = np.zeros((hidden_size, 1))\n",
    "        cprev = np.zeros((hidden_size, 1))\n",
    "        p = 0 \n",
    "    inputs = [char_to_ix[ch] for ch in data[p:p + seq_length]]\n",
    "    targets = [char_to_ix[ch] for ch in data[p + 1:p + seq_length + 1]]\n",
    "\n",
    "    \n",
    "    # forward seq_length characters through the net and fetch gradient\n",
    "    loss, hprev, cprev = lossFun(inputs, targets, hprev, cprev, params)\n",
    "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "    \n",
    "    if n % 100 == 0:\n",
    "        sample_ix = sample(hprev, cprev, inputs[0], 200, params)\n",
    "        txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "        print('----\\n %s \\n----' % (txt,))\n",
    "\n",
    "    if n % 100 == 0: \n",
    "        print('iter %d, loss: %f' % (n, smooth_loss))\n",
    "\n",
    "    \n",
    "    for key in list(params.keys()):\n",
    "        if key[0] != 'd' and key[0] != 'm':\n",
    "            mem_key = 'm_' + key\n",
    "            dkey = 'd' + key\n",
    "            params[mem_key] += params[dkey] * params[dkey]\n",
    "            params[key] += -learning_rate * params[dkey] / np.sqrt(params[mem_key] + 1e-8)\n",
    "    p += seq_length \n",
    "    n += 1\n",
    "\n"
   ]
  }
 ]
}